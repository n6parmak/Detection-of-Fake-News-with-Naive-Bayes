{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection of Fake News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd \n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "from string import digits\n",
    "os.chdir(r\"E:\\Masaüstü\\bbm409-assignment2\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft=pd.read_csv(\"fake_news_train.csv\")\n",
    "dft = dft.dropna(subset=['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting most weighted words in the titles\n",
    "tv = TfidfVectorizer(stop_words='english',smooth_idf=True)\n",
    "cv=CountVectorizer(stop_words='english')\n",
    "trueDocuments=[dft[\"title\"][i] for i in dft.index if dft[\"label\"][i]==0]\n",
    "falseDocuments=[dft[\"title\"][i] for i in dft.index if dft[\"label\"][i]==1]\n",
    "trueDocuments=\"\".join(x for x in trueDocuments)\n",
    "falseDocuments=\"\".join(x for x in falseDocuments)\n",
    "tv_score = tv.fit_transform([trueDocuments, falseDocuments]).toarray().tolist()\n",
    "cv_score = cv.fit_transform([trueDocuments, falseDocuments]).toarray().tolist()\n",
    "sortedTrue=sorted(range(len(tv_score[0])), key=lambda k: tv_score[0][k],reverse=True)\n",
    "sortedFalse=sorted(range(len(tv_score[1])), key=lambda k: tv_score[1][k],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 most weighted words for true titles\n",
      "true      false       word\n",
      "-----------------------------------------\n",
      "  0.529    0.152        new\n",
      "  0.511    0.011        york\n",
      "  0.180    0.420        trump\n",
      "  0.038    0.090        donald\n",
      "  0.032    0.000        timestrump\n"
     ]
    }
   ],
   "source": [
    "print(\"First 5 most weighted words for true titles\")\n",
    "print(\"true      false       word\")\n",
    "print(\"-\"*41) \n",
    "for i in sortedTrue[0:5]:\n",
    "    print(\"  {:.3f}    {:.3f}        {:}\".format(math.log(tv_score[0][i]+1),\n",
    "                                               math.log(tv_score[1][i]+1),cv.get_feature_names()[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new , york and timestrump words are the most repetitive words in true news titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 most weighted words for fake titles\n",
      "false      true       word\n",
      "-----------------------------------------\n",
      "  0.420    0.180        trump\n",
      "  0.317    0.015        hillary\n",
      "  0.303    0.029        clinton\n",
      "  0.152    0.529        new\n",
      "  0.148    0.012        election\n"
     ]
    }
   ],
   "source": [
    "print(\"First 5 most weighted words for fake titles\")\n",
    "print(\"false      true       word\")\n",
    "print(\"-\"*41) \n",
    "for i in sortedFalse[0:5]:\n",
    "    print(\"  {:.3f}    {:.3f}        {:}\".format(math.log(tv_score[1][i]+1),\n",
    "                                               math.log(tv_score[0][i]+1),cv.get_feature_names()[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trump , hillary clinton and election words are the most repetitive words in fake news titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implementing Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft=pd.read_csv(\"fake_news_train.csv\")\n",
    "dft = dft.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes(train,test,trainFeatures,testFeatures,target):\n",
    "    array=[]\n",
    "    arrayProb=[]\n",
    "    y=len(target)\n",
    "    target.index = pd.RangeIndex(len(target.index))\n",
    "    V=len(trainFeatures)#number of unique words\n",
    "    CT=sum([sum(train[i]) for i in target.index if target[i]==0])#true labelli dokümanlardaki kelime sayısı\n",
    "    CF=sum([sum(train[i]) for i in target.index if target[i]==1])#fake labelli dokümanlardaki kelime sayısı\n",
    "    numFalse=sum([target[i] for i in target.index if target[i]==1])#fake labelli döküman sayısı\n",
    "    numTrue=len(target)-numFalse#real labelli döküman sayısı\n",
    "    for i in range(len(trainFeatures)):\n",
    "        sumF=0\n",
    "        sumR=0\n",
    "        for j in target.index:\n",
    "            if(target[j]==1):\n",
    "                sumF+=train[j][i]#kelimenin fake labelli dokumanlarda kaç kez geçtiği\n",
    "            else:\n",
    "                sumR+=train[j][i]#kelimenin true labelli dokumanlarda kaç kez geçtiği\n",
    "            \n",
    "        array.append([math.log(((sumR+1)/(CT+V))),math.log(((sumF+1)/(CF+V)))])\n",
    "    test=csr_matrix(test)\n",
    "    \n",
    "    for i in set(csr_matrix.nonzero(test)[0]):\n",
    "        l=0\n",
    "        probForTrue=1\n",
    "        probForFalse=1\n",
    "        probForTrue=np.float64(probForTrue)\n",
    "        probForFalse=np.float64(probForFalse)\n",
    "        for y in csr_matrix.nonzero(test)[1]:\n",
    "            if(l==i):\n",
    "                if(testFeatures[y] in trainFeatures):\n",
    "                        index=trainFeatures.index(testFeatures[y])\n",
    "                        probForTrue+=(array[index][0])**test[i,y]\n",
    "                        probForFalse+=(array[index][1])**test[i,y]\n",
    "                else:  \n",
    "                    probForTrue+=math.log(((1)/(CT+V)))\n",
    "                    probForFalse+=math.log(((1)/(CF+V)))\n",
    "            l+=1        \n",
    "        probForTrue+=math.log((numTrue/y))\n",
    "        probForFalse+=math.log((numFalse/y))\n",
    "        if(probForTrue>probForFalse):\n",
    "            arrayProb.append(0)\n",
    "        else:\n",
    "            arrayProb.append(1)                                \n",
    "       \n",
    "       \n",
    "    return arrayProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing digits and stop words,transform to data a feature matrix\n",
    "#This method for unigram\n",
    "def testDataConverter(train,test):\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    train=[(str(s)).translate(remove_digits) for s in train]\n",
    "    test=[(str(s)).translate(remove_digits) for s in test]\n",
    "    vectorizer = CountVectorizer(stop_words='english')\n",
    "    X = vectorizer.fit_transform(train).toarray()\n",
    "    trainFeatures=vectorizer.get_feature_names()\n",
    "    y = vectorizer.fit_transform(test).toarray()\n",
    "    testFeatures=vectorizer.get_feature_names()\n",
    "    return X,y,trainFeatures,testFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method for biagram\n",
    "def testDataConverterBia(train,test):\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    train=[(str(s)).translate(remove_digits) for s in train]\n",
    "    test=[(str(s)).translate(remove_digits) for s in test]\n",
    "    vectorizer = CountVectorizer(stop_words='english',ngram_range=(2, 2))\n",
    "    X = vectorizer.fit_transform(train).toarray()\n",
    "    trainFeatures=vectorizer.get_feature_names()\n",
    "    y = vectorizer.fit_transform(test).toarray()\n",
    "    testFeatures=vectorizer.get_feature_names()\n",
    "    return X,y,trainFeatures,testFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(target,predicted):\n",
    "    cm=confusion_matrix(target, predicted)\n",
    "    accuracyScore=100*((cm[0][0]+cm[1][1])/len(target))\n",
    "    return accuracyScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE:due to time and memory issues data is sliced\n",
    "X = dft[\"text\"][0:500]\n",
    "y=dft[\"label\"][0:500]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,trainFeatures,testFeatures=testDataConverter(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unigram\n",
    "s=naiveBayes(X,y,trainFeatures,testFeatures,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_____',\n",
       " '________',\n",
       " '___krongard',\n",
       " '_alvin',\n",
       " '_native_life',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aabenraa',\n",
       " 'aaron',\n",
       " 'aaronkleinshow',\n",
       " 'ab',\n",
       " 'aback',\n",
       " 'abacus',\n",
       " 'abadi',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abandonment',\n",
       " 'abanico',\n",
       " 'abans']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example unigram's feature matrix\n",
    "trainFeatures[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#biagram\n",
    "X = dft[\"text\"][0:500]\n",
    "y=dft[\"label\"][0:500]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X,y,trainFeatures,testFeatures=testDataConverterBia(X_train,X_test)\n",
    "b=naiveBayes(X,y,trainFeatures,testFeatures,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abandon settlers',\n",
       " 'abandon ship',\n",
       " 'abandon troubled',\n",
       " 'abandoned according',\n",
       " 'abandoned base',\n",
       " 'abandoned bases',\n",
       " 'abandoned collapse',\n",
       " 'abandoned farmhouses',\n",
       " 'abandoned headquarters',\n",
       " 'abandoned house',\n",
       " 'abandoned ideals',\n",
       " 'abandoned kunduz',\n",
       " 'abandoned model',\n",
       " 'abandoned plan',\n",
       " 'abandoned plans',\n",
       " 'abandoned staff',\n",
       " 'abandoned substantive',\n",
       " 'abandoning manipulated',\n",
       " 'abandonment orders',\n",
       " 'abanico cada']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example biagram's feature matrix\n",
    "trainFeatures[50:70]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE:unigram and biagram model approach's accuracy will be tested at part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Analyzing eﬀect of the words on prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting most weighted words in the texts\n",
    "tv = TfidfVectorizer(stop_words='english',smooth_idf=True)\n",
    "cv=CountVectorizer(stop_words='english')\n",
    "trueDocuments=[dft[\"text\"][i] for i in dft.index if dft[\"label\"][i]==0]\n",
    "falseDocuments=[dft[\"text\"][i] for i in dft.index if dft[\"label\"][i]==1]\n",
    "trueDocuments=\"\".join(x for x in trueDocuments)\n",
    "falseDocuments=\"\".join(x for x in falseDocuments)\n",
    "tv_score = tv.fit_transform([trueDocuments, falseDocuments]).toarray().tolist()\n",
    "cv_score = cv.fit_transform([trueDocuments, falseDocuments]).toarray().tolist()\n",
    "sortedTrue=sorted(range(len(tv_score[0])), key=lambda k: tv_score[0][k],reverse=True)\n",
    "sortedFalse=sorted(range(len(tv_score[1])), key=lambda k: tv_score[1][k],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 most weighted words in the true news\n",
      "true      false       word\n",
      "-----------------------------------------\n",
      "  0.406    0.146        said\n",
      "  0.387    0.022        mr\n",
      "  0.233    0.237        trump\n",
      "  0.137    0.199        people\n",
      "  0.134    0.127        new\n",
      "  0.116    0.106        president\n",
      "  0.111    0.127        like\n",
      "  0.087    0.003        ms\n",
      "  0.084    0.116        time\n",
      "  0.081    0.131        just\n",
      "  0.080    0.082        years\n",
      "  0.080    0.113        state\n",
      "  0.077    0.084        states\n",
      "  0.072    0.068        year\n",
      "  0.072    0.063        united\n",
      "  0.067    0.070        news\n",
      "  0.066    0.062        did\n",
      "  0.064    0.088        american\n",
      "  0.061    0.103        government\n",
      "  0.059    0.049        house\n"
     ]
    }
   ],
   "source": [
    "print(\"First 20 most weighted words in the true news\")\n",
    "print(\"true      false       word\")\n",
    "print(\"-\"*41) \n",
    "for i in sortedTrue[0:20]:\n",
    "    print(\"  {:.3f}    {:.3f}        {:}\".format(math.log(tv_score[0][i]+1),\n",
    "                                               math.log(tv_score[1][i]+1),cv.get_feature_names()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 most weighted words for fake news\n",
      "false      true       word\n",
      "-----------------------------------------\n",
      "  0.237    0.233        trump\n",
      "  0.222    0.056        clinton\n",
      "  0.199    0.137        people\n",
      "  0.157    0.015        hillary\n",
      "  0.146    0.406        said\n",
      "  0.131    0.081        just\n",
      "  0.127    0.134        new\n",
      "  0.127    0.111        like\n",
      "  0.117    0.049        world\n",
      "  0.116    0.084        time\n",
      "  0.113    0.080        state\n",
      "  0.107    0.018        2016\n",
      "  0.106    0.116        president\n",
      "  0.103    0.061        government\n",
      "  0.103    0.032        election\n",
      "  0.096    0.052        obama\n",
      "  0.096    0.025        war\n",
      "  0.088    0.064        american\n",
      "  0.084    0.077        states\n",
      "  0.083    0.026        russia\n"
     ]
    }
   ],
   "source": [
    "print(\"First 20 most weighted words for fake news\")\n",
    "print(\"false      true       word\")\n",
    "print(\"-\"*41) \n",
    "for i in sortedFalse[0:20]:\n",
    "    print(\"  {:.3f}    {:.3f}        {:}\".format(math.log(tv_score[1][i]+1),\n",
    "                                               math.log(tv_score[0][i]+1),cv.get_feature_names()[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• List some words whose presence most strongly predicts that the news is real and\n",
    "whose absence most strongly predicts that the news is fake. -> said,mr,ms,house,new,president"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• List some words whose absence most strongly predicts that the news is real and\n",
    "whose presence most strongly predicts that the news is fake. -> russia,war,obama,election,2016,world,hillary clinton,government,time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#above algoritm eliminate stop words below algoritm do not\n",
    "tv = TfidfVectorizer(smooth_idf=True)\n",
    "cv=CountVectorizer()\n",
    "trueDocuments=[dft[\"text\"][i] for i in dft.index if dft[\"label\"][i]==0]\n",
    "falseDocuments=[dft[\"text\"][i] for i in dft.index if dft[\"label\"][i]==1]\n",
    "trueDocuments=\"\".join(x for x in trueDocuments)\n",
    "falseDocuments=\"\".join(x for x in falseDocuments)\n",
    "tv_score = tv.fit_transform([trueDocuments, falseDocuments]).toarray().tolist()\n",
    "cv_score = cv.fit_transform([trueDocuments, falseDocuments]).toarray().tolist()\n",
    "sortedTrue=sorted(range(len(tv_score[0])), key=lambda k: tv_score[0][k],reverse=True)\n",
    "sortedFalse=sorted(range(len(tv_score[1])), key=lambda k: tv_score[1][k],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 most weighted words in the true news (include stopwords)\n",
      "true      false       word\n",
      "-----------------------------------------\n",
      "  0.525    0.521        the\n",
      "  0.274    0.281        to\n",
      "  0.266    0.280        of\n",
      "  0.245    0.262        and\n",
      "  0.218    0.197        in\n",
      "  0.152    0.150        that\n",
      "  0.105    0.100        for\n",
      "  0.101    0.083        on\n",
      "  0.093    0.046        he\n",
      "  0.091    0.137        is\n"
     ]
    }
   ],
   "source": [
    "print(\"First 10 most weighted words in the true news (include stopwords)\")\n",
    "print(\"true      false       word\")\n",
    "print(\"-\"*41) \n",
    "for i in sortedTrue[0:10]:\n",
    "    print(\"  {:.3f}    {:.3f}        {:}\".format(math.log(tv_score[0][i]+1),\n",
    "                                               math.log(tv_score[1][i]+1),cv.get_feature_names()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 most weighted words for fake news (include stopwords)\n",
      "false      true       word\n",
      "-----------------------------------------\n",
      "  0.521    0.525        the\n",
      "  0.281    0.274        to\n",
      "  0.280    0.266        of\n",
      "  0.262    0.245        and\n",
      "  0.197    0.218        in\n",
      "  0.150    0.152        that\n",
      "  0.137    0.091        is\n",
      "  0.100    0.105        for\n",
      "  0.093    0.087        it\n",
      "  0.083    0.101        on\n"
     ]
    }
   ],
   "source": [
    "print(\"First 10 most weighted words for fake news (include stopwords)\")\n",
    "print(\"false      true       word\")\n",
    "print(\"-\"*41) \n",
    "for i in sortedFalse[0:10]:\n",
    "    print(\"  {:.3f}    {:.3f}        {:}\".format(math.log(tv_score[1][i]+1),\n",
    "                                               math.log(tv_score[0][i]+1),cv.get_feature_names()[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Analyzing eﬀect of the stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is seen, eliminating stopwords from text is critic.Stopwords are meaningless to predict data and they are waste of time and memory for program due to repetiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Calculation of Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of unigram :  49.0\n",
      "Accuracy of biagram :  51.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of unigram : \",accuracy(y_test,s))\n",
    "print(\"Accuracy of biagram : \",accuracy(y_test,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is seen biagram model is slightly more successfull to predict data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to analyse and test result preprocessing data is critic (e.g:eliminating stop words),\n",
    "biagram approuch can be more proper for this dataset and bigger datasets can predict data more accurate\n",
    "(due to the time and memory issues, a small amount of data is used in this report therefore accuracies are low.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
